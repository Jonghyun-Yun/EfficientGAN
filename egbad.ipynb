{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install ~/cloudfiles/code/software/PyPeanuts/latest/peanuts-0.6.5-py3-none-any.whl --force-reinstall"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#!conda env list"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "# conda environments:\r\n#\r\nbase                  *  /anaconda\r\nazureml_py36             /anaconda/envs/azureml_py36\r\nazureml_py38             /anaconda/envs/azureml_py38\r\nazureml_py38_PT_TF       /anaconda/envs/azureml_py38_PT_TF\r\n\r\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import peanuts\r\n",
        "from peanuts.AML.orion import *\r\n",
        "\r\n",
        "username='746220'\r\n",
        "orion = Orion(user=username)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ðŸ””\u001b[1m Just a Reminder: Is your key vault name following the naming convention: ba-<n|p>-z<eaus|weus>-<user>-kv? If NO, please specify your key vault name.\u001b[0m\nðŸ””\u001b[1m Just a Reminder: Do you have a secret with name corpaaid-pw stored in your key vault? If NO, please specify your secret name.\u001b[0m\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649105113537
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_path_loader(data_source, scoring_training_ind):\r\n",
        "    \"\"\"\r\n",
        "    This function loads query paths based on input args.\r\n",
        "    We have saved queries in these locations.\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    if data_source == 'trans':\r\n",
        "      if scoring_training_ind=='training':\r\n",
        "        sql_path=\"AWD_TRANS_Databricks_Query.sql\"  # _Feb24-1.txt\"\r\n",
        "      else:\r\n",
        "        # sql_path=\"/dbfs/FileStore/tables/data_query_test_Mar4.txt\"\r\n",
        "        sql_path=\"AWD_TRANS_Databricks_Query.sql\"\r\n",
        "#       data_query_updated_Feb-1.txt\"\r\n",
        "      #data_query_Jan-3.txt\" data_query_Jan_vol.txt\"  data_query_Jan_vol_cast.txt\r\n",
        "#     elif data_source == \"clickstream\":\r\n",
        "#             sql_path = \"./\"\r\n",
        "    return sql_path\r\n",
        "\r\n",
        "# sql_path_loader('trans')\r\n",
        "\r\n",
        "def sql_renderer(data_source, scoring_training_ind, start_date, end_date, binHist='(1)', print_sql=False):\r\n",
        "    \"\"\"\r\n",
        "    This function renders the query based on input args\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    sql_path = sql_path_loader(data_source = data_source, scoring_training_ind=scoring_training_ind )\r\n",
        "    sql = open(sql_path, 'r').read()\r\n",
        "#     if scoring_training_ind=='training':\r\n",
        "    sql = sql.format(lb=start_date, ub=end_date, binHist=binHist)\r\n",
        "#     else:\r\n",
        "#       sql = sql.format(CURRENT_DATE=date)\r\n",
        "    if print_sql:\r\n",
        "        print(sql)\r\n",
        "    return sql\r\n",
        "  \r\n",
        "def data_retriever_fun(data_source,scoring_training_ind, start_date, end_date, binHist, print_sql):\r\n",
        "    \"\"\"\r\n",
        "    This function retrieves records from mosaic tables\r\n",
        "    \"\"\"\r\n",
        "        \r\n",
        "    if (data_source != \"trans\") & (data_source != \"clickstream\"):\r\n",
        "        print(\"### ERROR: data source should be either trans or clickstream ###\")\r\n",
        "        return\r\n",
        "    elif (start_date == None):\r\n",
        "        print(\"### ERROR: Provide date in format of 'yyyy-mm-dd' ###\")\r\n",
        "        return\r\n",
        "    else:\r\n",
        "            sql = sql_renderer(data_source = data_source, scoring_training_ind=scoring_training_ind, start_date=start_date, end_date=end_date, binHist=binHist, print_sql = print_sql)\r\n",
        "            retrieved_df = orion.mq(sql)#pd.read_sql(sql)\r\n",
        "            return retrieved_df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648739966356
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sql_path=\"AWD_TRANS_Databricks_Query.sql\"\r\n",
        "#sql = open(sql_path, 'r').read()\r\n",
        "#start_date='2022-03-24'\r\n",
        "#end_date='2022-03-30'\r\n",
        "#sql = sql.format(lb=start_date, ub=end_date, binHist='(1)')\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648739932322
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_test=data_retriever_fun(data_source='trans', scoring_training_ind='scoring', start_date='2022-03-24', end_date='2022-03-30', binHist = '(1)', print_sql=False)\r\n",
        "sdf=data_retriever_fun(data_source='trans', scoring_training_ind='training', start_date='2022-02-23', end_date='2022-03-23', binHist='(1)', print_sql=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648740219362
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sdf.display()\r\n",
        "# without filter\r\n",
        "indices=['LYLTY_ACCT_ID', 'PNR_LOCTR_ID', 'PNR_CREATE_DT', 'AWD_PKG_ISSUE_DT']\r\n",
        "categorical=['OPERAT_AIRLN','ORIGIN_RM_WRLD_REGION_CD','DESTNTN_RM_WRLD_REGION_CD']\r\n",
        "#, 'OPERAT_AIRLN_IATA_CD2', 'OD_ORIGIN_AIRPRT_IATA_CD','OD_DESTNTN_AIRPRT_IATA_CD','ORIGIN_CNTRY_CD','ORIGIN_RM_WRLD_REGION_CD','DESTNTN_CNTRY_CD','DESTNTN_RM_WRLD_REGION_CD'\r\n",
        "#  'VISITED_BEFORE_STATE'\r\n",
        "#'AWD_LEVEL_MILE_QTY','NUM_PAX','SAFE_AIRPRT_IND','FLAGGED_AIRPRT_IND', \r\n",
        "numericals=['AP','PAX_LYLTY_IND', \r\n",
        "            'VISITED_BEFORE_AIRPORT',\r\n",
        "            #'VISITED_BEFORE_CNTRY',\r\n",
        "            'USED_BEFORE_ARILN',\r\n",
        "            'ONE_WAY', 'SHORT_AP_OK',\r\n",
        "            'SEEN_ITIN',\r\n",
        "            #'SAFE_VS_FLAGGED_CNTRY', \r\n",
        "            'BIN_HIST', 'MULTI_REDEEM', 'EMAIL_CHANGE30', \r\n",
        "            'U_AP', 'AGE45', 'AGE_logEMAIL',\r\n",
        "            'LAST_EMAIL',\r\n",
        "            'AGE_LAST_EMAIL',\r\n",
        "            #'HOME_AIRPRT',\r\n",
        "            #'HOME_STATE',\r\n",
        "            #'HOME_RESDNC_CNTRY',\r\n",
        "            #'HOME_ADV',\r\n",
        "            'FLAGGED_CNTRY_ALERT',\r\n",
        "            'FLAGGED_AIRPRT_ALERT',\r\n",
        "            'risk_feature1', \r\n",
        "            'risk_feature2',\r\n",
        "            'risk_feature3',\r\n",
        "            'risk_feature4',\r\n",
        "            'risk_feature5',\r\n",
        "            'risk_feature6',\r\n",
        " #           'safe_feature1',\r\n",
        " #           'FREQ_USED_ARILN',\r\n",
        " #           'FREQ_DESTNTN_CNTRY',\r\n",
        " #           'FREQ_ORIGIN_CNTRY',\r\n",
        " #           'FREQ_CNTRY',\r\n",
        "#            'FREQ_ORIGIN_AIRPRT',\r\n",
        "#            'FREQ_DESTNTN_AIRPRT',\r\n",
        " #           'FREQ_AIRPORT',\r\n",
        "           ]\r\n",
        "\r\n",
        "# 'FLAGGED_CNTRY_ALERT', 'SAFE_CNTRY_OK',\r\n",
        "#  'SAFE_VS_FLAGGED_CNTRY',\r\n",
        "#  'NUM_HIST',\r\n",
        "#  'DAYS_SINCE_LAST'\r\n",
        "predictors=numericals+categorical"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648739933823
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdfNorm = sdf.query('(BIN_HIST == 1) & ((LAST_NM_MATCH == 1) | (OWNER_IN_FLIGHT == 1) | (PAX_REDEEMED_BEFORE == 1) | (FLOWN_PAX == 1))')\r\n",
        "sdfNorm = sdfNorm.drop_duplicates()\r\n",
        "\r\n",
        "#sdfFiltered = sdf.filter((sdf.OWNER_IN_FLIGHT != 1) & (sdf.BIN_HIST == 1))\r\n",
        "\r\n",
        "sdf_test_clean = sdf_test.query('((RAW_AP <= 9) & (BIN_HIST == 1)) & ~((LAST_NM_MATCH == 1) | (OWNER_IN_FLIGHT == 1) | (PAX_REDEEMED_BEFORE == 1) | (FLOWN_PAX == 1))')\r\n",
        "sdf_test_clean = sdf_test_clean.drop_duplicates()\r\n",
        "#predictions=model.transform(sdf_test_clean)\r\n",
        "\r\n",
        "#& sdf.OWNER_IN_FLIGHT != 1 & sdf.PAX_REDEEMED_BEFORE != 1 & sdf.ONE_WAY != 1)\r\n",
        "\r\n",
        "numAfter = len(sdfNorm)\r\n",
        "numBefore = len(sdf)\r\n",
        "print(f\"rows of normal instances {numAfter}\")\r\n",
        "print(f\"rows of all instances {numBefore}\")\r\n",
        "print(f\"reduction percentage AFTER filtering {round(numAfter / numBefore * 100, 2)}\")\r\n",
        "\r\n",
        "sdf = sdfNorm\r\n",
        "\r\n",
        "print(f\"rows AFTER filtering {len(sdf_test_clean)}\")\r\n",
        "print(f\"rows BEFORE filtering {len(sdf_test)}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648739941060
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import logging\r\n",
        "import importlib\r\n",
        "import sys\r\n",
        "from sklearn.metrics import precision_recall_fscore_support\r\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649105169594
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aa = dfTest.nsmallest(n=100, columns='decision_function')\r\n",
        "aa.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648738940928
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aa.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense\r\n",
        "from keras.models import Model, Sequential\r\n",
        "from keras import regularizers\r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import classification_report, accuracy_score\r\n",
        "from sklearn.manifold import TSNE\r\n",
        "from sklearn import preprocessing \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "import seaborn as sns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648143628537
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\r\n",
        "print(sys.version)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648217013948
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install cv2\n",
        "\n",
        "import matplotlib\n",
        "\n",
        "import os\n",
        "#import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Reshape, Dense, Dropout, MaxPooling2D, Conv2D, Flatten\n",
        "from keras.layers import Conv2DTranspose, LeakyReLU\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "from keras.utils. generic_utils import Progbar\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from typing import Tuple\n",
        "from keras.models import load_model\n",
        "from sklearn.manifold import TSNE\n",
        "from keras.layers import concatenate\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import copy\n",
        "from enum import Enum\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "import io\n",
        "from PIL import Image\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from math import floor\n",
        "#from skimage.transform import resize\n",
        "from scipy.linalg import sqrtm"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649108449489
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "azureml_py38_pt_tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "azureml_py38_pt_tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}