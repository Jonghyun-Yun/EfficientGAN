{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!conda install -n tf_2.3.1 python=3.8.3\n",
        "#!conda activate tf_2.3.1\n",
        "#!pip install --upgrade tensorflow-2.3.1\n",
        "#!conda install scikit-learn\n",
        "#!pip install ~/cloudfiles/code/software/PyPeanuts/latest/peanuts-0.6.5-py3-none-any.whl --force-reinstall"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1649370751398
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import peanuts\r\n",
        "from peanuts.AML.orion import *\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "print(tf.version.VERSION) # shuold be 2.3.1\r\n",
        "from model import EfficientGAN\r\n",
        "\r\n",
        "username='746220'\r\n",
        "orion = Orion(user=username)\r\n",
        "\r\n",
        "#import umap\r\n",
        "#import umap.plot\r\n",
        "#import matplotlib.pyplot as plt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-04-07 22:32:38.764492: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n2022-04-07 22:32:38.764560: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2.3.1\nðŸ””\u001b[1m Just a Reminder: Is your key vault name following the naming convention: ba-<n|p>-z<eaus|weus>-<user>-kv? If NO, please specify your key vault name.\u001b[0m\nðŸ””\u001b[1m Just a Reminder: Do you have a secret with name corpaaid-pw stored in your key vault? If NO, please specify your secret name.\u001b[0m\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649370776336
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_path_loader(data_source, scoring_training_ind):\r\n",
        "    \"\"\"\r\n",
        "    This function loads query paths based on input args.\r\n",
        "    We have saved queries in these locations.\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    if data_source == 'trans':\r\n",
        "      if scoring_training_ind=='training':\r\n",
        "        sql_path=\"../AWD_TRANS_Databricks_Query.sql\"  # _Feb24-1.txt\"\r\n",
        "      else:\r\n",
        "        # sql_path=\"/dbfs/FileStore/tables/data_query_test_Mar4.txt\"\r\n",
        "        sql_path=\"../AWD_TRANS_Databricks_Query.sql\"\r\n",
        "#       data_query_updated_Feb-1.txt\"\r\n",
        "      #data_query_Jan-3.txt\" data_query_Jan_vol.txt\"  data_query_Jan_vol_cast.txt\r\n",
        "#     elif data_source == \"clickstream\":\r\n",
        "#             sql_path = \"./\"\r\n",
        "    return sql_path\r\n",
        "\r\n",
        "# sql_path_loader('trans')\r\n",
        "\r\n",
        "def sql_renderer(data_source, scoring_training_ind, start_date, end_date, print_sql=False):\r\n",
        "    \"\"\"\r\n",
        "    This function renders the query based on input args\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    sql_path = sql_path_loader(data_source = data_source, scoring_training_ind=scoring_training_ind )\r\n",
        "    sql = open(sql_path, 'r').read()\r\n",
        "#     if scoring_training_ind=='training':\r\n",
        "    sql = sql.format(lb=start_date, ub=end_date)\r\n",
        "#     else:\r\n",
        "#       sql = sql.format(CURRENT_DATE=date)\r\n",
        "    if print_sql:\r\n",
        "        print(sql)\r\n",
        "    return sql\r\n",
        "  \r\n",
        "def data_retriever_fun(data_source,scoring_training_ind, start_date, end_date, print_sql):\r\n",
        "    \"\"\"\r\n",
        "    This function retrieves records from mosaic tables\r\n",
        "    \"\"\"\r\n",
        "        \r\n",
        "    if (data_source != \"trans\") & (data_source != \"clickstream\"):\r\n",
        "        print(\"### ERROR: data source should be either trans or clickstream ###\")\r\n",
        "        return\r\n",
        "    elif (start_date == None):\r\n",
        "        print(\"### ERROR: Provide date in format of 'yyyy-mm-dd' ###\")\r\n",
        "        return\r\n",
        "    else:\r\n",
        "            sql = sql_renderer(data_source = data_source, scoring_training_ind=scoring_training_ind, \r\n",
        "            start_date=start_date, end_date=end_date, print_sql = print_sql)\r\n",
        "            retrieved_df = orion.mq(sql)#pd.read_sql(sql)\r\n",
        "            return retrieved_df"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649370776702
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_test=data_retriever_fun(data_source='trans', scoring_training_ind='scoring', start_date='2022-03-30', end_date='2022-04-05', print_sql=False)\r\n",
        "sdf=data_retriever_fun(data_source='trans', scoring_training_ind='training', start_date='2022-02-28', end_date='2022-03-29', print_sql=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\npandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649371778934
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sdf.display()\r\n",
        "# without filter\r\n",
        "indices=['LYLTY_ACCT_ID', 'PNR_LOCTR_ID', 'PNR_CREATE_DT', 'AWD_PKG_ISSUE_DT']\r\n",
        "categorical=['OPERAT_AIRLN','ORIGIN_RM_WRLD_REGION_CD','DESTNTN_RM_WRLD_REGION_CD']\r\n",
        "#, 'OPERAT_AIRLN_IATA_CD2', 'OD_ORIGIN_AIRPRT_IATA_CD','OD_DESTNTN_AIRPRT_IATA_CD','ORIGIN_CNTRY_CD','ORIGIN_RM_WRLD_REGION_CD','DESTNTN_CNTRY_CD','DESTNTN_RM_WRLD_REGION_CD'\r\n",
        "#  'VISITED_BEFORE_STATE'\r\n",
        "#'AWD_LEVEL_MILE_QTY','NUM_PAX','SAFE_AIRPRT_IND','FLAGGED_AIRPRT_IND', \r\n",
        "numericals=['AP','PAX_LYLTY_IND', \r\n",
        "            'VISITED_BEFORE_AIRPORT',\r\n",
        "            #'VISITED_BEFORE_CNTRY',\r\n",
        "            'USED_BEFORE_ARILN',\r\n",
        "            'ONE_WAY', 'SHORT_AP_OK',\r\n",
        "            'SEEN_ITIN',\r\n",
        "            #'SAFE_VS_FLAGGED_CNTRY', \r\n",
        "            'BIN_HIST', 'MULTI_REDEEM', 'EMAIL_CHANGE30', \r\n",
        "            'U_AP', 'AGE45', 'AGE_logEMAIL',\r\n",
        "            'LAST_EMAIL',\r\n",
        "            'AGE_LAST_EMAIL',\r\n",
        "            #'HOME_AIRPRT',\r\n",
        "            #'HOME_STATE',\r\n",
        "            #'HOME_RESDNC_CNTRY',\r\n",
        "            #'HOME_ADV',\r\n",
        "            'FLAGGED_CNTRY_ALERT',\r\n",
        "            'FLAGGED_AIRPRT_ALERT',\r\n",
        "            'risk_feature1', \r\n",
        "            'risk_feature2',\r\n",
        "            'risk_feature3',\r\n",
        "            'risk_feature4',\r\n",
        "            #'risk_feature5',\r\n",
        "            'risk_feature6',\r\n",
        " #           'safe_feature1',\r\n",
        " #           'FREQ_USED_ARILN',\r\n",
        " #           'FREQ_DESTNTN_CNTRY',\r\n",
        " #           'FREQ_ORIGIN_CNTRY',\r\n",
        " #           'FREQ_CNTRY',\r\n",
        "#            'FREQ_ORIGIN_AIRPRT',\r\n",
        "#            'FREQ_DESTNTN_AIRPRT',\r\n",
        " #           'FREQ_AIRPORT',\r\n",
        "           ]\r\n",
        "\r\n",
        "# 'FLAGGED_CNTRY_ALERT', 'SAFE_CNTRY_OK',\r\n",
        "#  'SAFE_VS_FLAGGED_CNTRY',\r\n",
        "#  'NUM_HIST',\r\n",
        "#  'DAYS_SINCE_LAST'\r\n",
        "predictors=numericals+categorical"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649371779098
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sdfNorm = sdf.query('(BIN_HIST == 1) & (NORMAL_TRAN == 1)')\r\n",
        "sdfNorm = sdf.query('(BIN_HIST == 1) & ((NORMAL_TRAN == 1) | (FLOWN_LAST_NM == 1) | (RED_LAST_NM == 1) | (IP_MATCH == 1))')\r\n",
        "\r\n",
        "sdfNorm = sdfNorm.drop_duplicates()\r\n",
        "#sdfFiltered = sdf.filter((sdf.OWNER_IN_FLIGHT != 1) & (sdf.BIN_HIST == 1))\r\n",
        "\r\n",
        "#sdf_test_clean = sdf_test.query('((BIN_HIST == 1) & (RAW_AP <= 9) & ~(NORMAL_TRAN == 1))')\r\n",
        "sdf_test_clean = sdf_test.query('((BIN_HIST == 1) & (RAW_AP <= 9) & ~((NORMAL_TRAN == 1) | (FLOWN_LAST_NM == 1) | (RED_LAST_NM == 1) | (IP_MATCH == 1)))')\r\n",
        "sdf_test_clean = sdf_test_clean.drop_duplicates()\r\n",
        "#predictions=model.transform(sdf_test_clean)\r\n",
        "\r\n",
        "#& sdf.OWNER_IN_FLIGHT != 1 & sdf.PAX_REDEEMED_BEFORE != 1 & sdf.ONE_WAY != 1)\r\n",
        "\r\n",
        "numAfter = len(sdfNorm)\r\n",
        "numBefore = len(sdf)\r\n",
        "print(f\"rows of normal instances {numAfter}\")\r\n",
        "print(f\"rows of all instances {numBefore}\")\r\n",
        "print(f\"reduction percentage AFTER filtering {round(numAfter / numBefore * 100, 2)}\")\r\n",
        "\r\n",
        "print(f\"rows AFTER filtering {len(sdf_test_clean)}\")\r\n",
        "print(f\"rows BEFORE filtering {len(sdf_test)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "rows of normal instances 346179\nrows of all instances 556564\nreduction percentage AFTER filtering 62.2\nrows AFTER filtering 1125\nrows BEFORE filtering 95253\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649371783640
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\r\n",
        "from sklearn.preprocessing import LabelEncoder# creating initial dataframe\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "df = sdfNorm\r\n",
        "dfTest = sdf_test_clean\r\n",
        "\r\n",
        "le = LabelEncoder()\r\n",
        "dfCopy = df[predictors].copy()\r\n",
        "dfTestCopy = dfTest[predictors].copy()\r\n",
        "\r\n",
        "#for col in categorical:\r\n",
        "#  dfCopy[col] = le.fit_transform(dfCopy[col])\r\n",
        "#  dfTestCopy[col] = le.fit_transform(dfTestCopy[col])\r\n",
        "\r\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\r\n",
        "ohTrain = pd.DataFrame(ohe.fit_transform(dfCopy[categorical]))\r\n",
        "ohTest = pd.DataFrame(ohe.transform(dfTestCopy[categorical]))\r\n",
        "\r\n",
        "# Adding column names to the encoded data set.\r\n",
        "ohTrain.columns = ohe.get_feature_names_out(categorical)\r\n",
        "ohTest.columns = ohe.get_feature_names_out(categorical)\r\n",
        "\r\n",
        "# One-hot encoding removed index; put it back\r\n",
        "ohTrain.index = dfCopy.index\r\n",
        "ohTest.index = dfTestCopy.index\r\n",
        "\r\n",
        "# Remove categorical columns (will replace with one-hot encoding)\r\n",
        "dfCopy = dfCopy.drop(categorical, axis=1)\r\n",
        "dfTestCopy = dfTestCopy.drop(categorical, axis=1)\r\n",
        "\r\n",
        "# Add one-hot encoded columns to numerical features\r\n",
        "dfCopy = pd.concat([dfCopy, ohTrain], axis=1)\r\n",
        "dfTestCopy = pd.concat([dfTestCopy, ohTest], axis=1)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649371785687
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfTestCopy.shape\n",
        "dfCopy.shape\n",
        "dfCopy.columns"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "Index(['AP', 'PAX_LYLTY_IND', 'VISITED_BEFORE_AIRPORT', 'USED_BEFORE_ARILN',\n       'ONE_WAY', 'SHORT_AP_OK', 'SEEN_ITIN', 'BIN_HIST', 'MULTI_REDEEM',\n       'EMAIL_CHANGE30', 'U_AP', 'AGE45', 'AGE_logEMAIL', 'LAST_EMAIL',\n       'AGE_LAST_EMAIL', 'FLAGGED_CNTRY_ALERT', 'FLAGGED_AIRPRT_ALERT',\n       'risk_feature1', 'risk_feature2', 'risk_feature3', 'risk_feature4',\n       'risk_feature6', 'OPERAT_AIRLN_0', 'OPERAT_AIRLN_1', 'OPERAT_AIRLN_2',\n       'ORIGIN_RM_WRLD_REGION_CD_AF', 'ORIGIN_RM_WRLD_REGION_CD_AS',\n       'ORIGIN_RM_WRLD_REGION_CD_CA', 'ORIGIN_RM_WRLD_REGION_CD_CR',\n       'ORIGIN_RM_WRLD_REGION_CD_EU', 'ORIGIN_RM_WRLD_REGION_CD_ME',\n       'ORIGIN_RM_WRLD_REGION_CD_NA', 'ORIGIN_RM_WRLD_REGION_CD_OC',\n       'ORIGIN_RM_WRLD_REGION_CD_SA', 'DESTNTN_RM_WRLD_REGION_CD_AF',\n       'DESTNTN_RM_WRLD_REGION_CD_AS', 'DESTNTN_RM_WRLD_REGION_CD_CA',\n       'DESTNTN_RM_WRLD_REGION_CD_CR', 'DESTNTN_RM_WRLD_REGION_CD_EU',\n       'DESTNTN_RM_WRLD_REGION_CD_ME', 'DESTNTN_RM_WRLD_REGION_CD_NA',\n       'DESTNTN_RM_WRLD_REGION_CD_OC', 'DESTNTN_RM_WRLD_REGION_CD_SA'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649371785863
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = EfficientGAN()\r\n",
        "model.fit(dfCopy, epochs=500, batch_size=1024)\r\n",
        "proba = model.predict(dfTestCopy)\r\n",
        "dfTest['decision_function'] = proba"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-04-07 22:49:45.634928: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n2022-04-07 22:49:46.667680: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n2022-04-07 22:49:46.667778: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ba-p-zeaus-746220sazmlci): /proc/driver/nvidia/version does not exist\n2022-04-07 22:49:46.669090: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-04-07 22:49:46.762849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2095245000 Hz\n2022-04-07 22:49:46.763376: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5628d9a3d550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2022-04-07 22:49:46.763424: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "epoch0-> d_loss:0.9358741790056229  e_loss:13.949773788452148  g_loss:0.6118311882019043\nepoch10-> d_loss:0.9526254236698151  e_loss:10.719099998474121  g_loss:0.6175879240036011\nepoch20-> d_loss:1.156915545463562  e_loss:9.620051383972168  g_loss:0.6180082559585571\nepoch30-> d_loss:1.3672295808792114  e_loss:7.5071563720703125  g_loss:0.6075266599655151\nepoch40-> d_loss:1.7185212969779968  e_loss:6.337667465209961  g_loss:0.6169198751449585\nepoch50-> d_loss:2.0528809428215027  e_loss:5.112499237060547  g_loss:0.6026747226715088\nepoch60-> d_loss:2.3990713357925415  e_loss:4.306389331817627  g_loss:0.6154841780662537\nepoch70-> d_loss:2.5784838795661926  e_loss:3.483208179473877  g_loss:0.6087245345115662\nepoch80-> d_loss:2.8176766633987427  e_loss:3.380417585372925  g_loss:0.6036961078643799\nepoch90-> d_loss:3.277631103992462  e_loss:3.2735955715179443  g_loss:0.6128025650978088\nepoch100-> d_loss:3.5771483182907104  e_loss:2.967963218688965  g_loss:0.6060472726821899\nepoch110-> d_loss:3.3953744769096375  e_loss:3.111462116241455  g_loss:0.5992540121078491\nepoch120-> d_loss:3.515323042869568  e_loss:2.6952402591705322  g_loss:0.6126315593719482\nepoch130-> d_loss:3.793198585510254  e_loss:2.315822124481201  g_loss:0.6053488254547119\nepoch140-> d_loss:3.6398415565490723  e_loss:2.4247002601623535  g_loss:0.5886701345443726\nepoch150-> d_loss:3.6539299488067627  e_loss:2.49499249458313  g_loss:0.5802123546600342\nepoch160-> d_loss:3.3817840218544006  e_loss:2.608340263366699  g_loss:0.5805661082267761\nepoch170-> d_loss:3.5253230333328247  e_loss:2.047100782394409  g_loss:0.58439040184021\nepoch180-> d_loss:3.747271478176117  e_loss:2.6580698490142822  g_loss:0.565222978591919\nepoch190-> d_loss:3.78972852230072  e_loss:2.6128196716308594  g_loss:0.5888489484786987\nepoch200-> d_loss:3.8730920553207397  e_loss:2.2913031578063965  g_loss:0.5794782638549805\nepoch210-> d_loss:3.401863932609558  e_loss:2.446593761444092  g_loss:0.586248517036438\nepoch220-> d_loss:3.600607931613922  e_loss:2.3409178256988525  g_loss:0.5759067535400391\nepoch230-> d_loss:3.6917120218276978  e_loss:2.184757947921753  g_loss:0.5789000988006592\nepoch240-> d_loss:3.446852445602417  e_loss:2.318711519241333  g_loss:0.5673761367797852\nepoch250-> d_loss:3.3869128227233887  e_loss:2.538639545440674  g_loss:0.5739249587059021\nepoch260-> d_loss:3.558751106262207  e_loss:2.390259265899658  g_loss:0.562859296798706\nepoch270-> d_loss:3.5405184030532837  e_loss:2.0682897567749023  g_loss:0.5599749088287354\nepoch280-> d_loss:3.435177803039551  e_loss:2.3210325241088867  g_loss:0.5703710317611694\nepoch290-> d_loss:3.4642449021339417  e_loss:2.032827854156494  g_loss:0.562768280506134\nepoch300-> d_loss:3.7446696162223816  e_loss:2.2608306407928467  g_loss:0.5600724220275879\nepoch310-> d_loss:3.567074239253998  e_loss:2.0769522190093994  g_loss:0.5605482459068298\nepoch320-> d_loss:3.659971237182617  e_loss:2.139425754547119  g_loss:0.5696808099746704\nepoch330-> d_loss:3.824753224849701  e_loss:2.175097942352295  g_loss:0.538891077041626\nepoch340-> d_loss:3.4966660737991333  e_loss:2.4344534873962402  g_loss:0.5687123537063599\nepoch350-> d_loss:3.345796823501587  e_loss:2.2670302391052246  g_loss:0.55763179063797\nepoch360-> d_loss:3.400523364543915  e_loss:2.0953760147094727  g_loss:0.5389205813407898\nepoch370-> d_loss:3.563882350921631  e_loss:1.965853214263916  g_loss:0.5533585548400879\nepoch380-> d_loss:3.5555537343025208  e_loss:2.249634027481079  g_loss:0.5447490215301514\nepoch390-> d_loss:3.1574313640594482  e_loss:2.092318534851074  g_loss:0.565199613571167\nepoch400-> d_loss:3.382439970970154  e_loss:2.043992519378662  g_loss:0.5314808487892151\nepoch410-> d_loss:3.874647080898285  e_loss:1.8251277208328247  g_loss:0.5359260439872742\nepoch420-> d_loss:3.5573328733444214  e_loss:2.4288864135742188  g_loss:0.546799898147583\nepoch430-> d_loss:3.5026869773864746  e_loss:1.9357171058654785  g_loss:0.5411545038223267\nepoch440-> d_loss:3.132169246673584  e_loss:2.3644590377807617  g_loss:0.5455281734466553\nepoch450-> d_loss:3.372331440448761  e_loss:2.1673078536987305  g_loss:0.5539189577102661\nepoch460-> d_loss:3.3032957315444946  e_loss:2.304368734359741  g_loss:0.534369945526123\nepoch470-> d_loss:3.3919124603271484  e_loss:2.1817688941955566  g_loss:0.5456780195236206\nepoch480-> d_loss:3.6711496114730835  e_loss:2.152346134185791  g_loss:0.5302278995513916\nepoch490-> d_loss:3.1292643547058105  e_loss:1.9799718856811523  g_loss:0.527086615562439\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649371853370
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = dfTest.copy()\n",
        "#out = out.nsmallest(n=100, columns='decision_function').copy()\n",
        "#out.groupby(out.LYLTY_ACCT_ID).first().display()\n",
        "out = dfTest.groupby(out.LYLTY_ACCT_ID).apply(lambda x: x.loc[x['decision_function'].idxmax()]).nlargest(n=100, columns='decision_function').copy()\n",
        "#out = out.reset_index()\n",
        "out.to_csv('../GANres220330-040.csv')"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649371854717
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfTest.nlargest(n=100, columns='decision_function')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "        LYLTY_ACCT_ID PNR_LOCTR_ID PNR_CREATE_DT AWD_PKG_ISSUE_DT  \\\n4817   M546732              FKSZNB    2022-04-01       2022-04-01   \n34387  PDB4246              HHEZUP    2022-03-26       2022-03-26   \n18976  965T5L4              UPMFKA    2022-04-01       2022-04-01   \n27643  965T5L4              UPMFKA    2022-04-01       2022-04-01   \n8167   965T5L4              VUEINX    2022-04-01       2022-04-01   \n...               ...          ...           ...              ...   \n68171  2E34VP2              SRRHGO    2022-03-24       2022-03-25   \n33139  2KB1E70              HSUKDP    2022-04-02       2022-04-02   \n12906  287T7R4              CBFBUR    2022-03-27       2022-03-28   \n56017  4AF6858              VSPLBB    2022-03-23       2022-03-23   \n79834  9Y02Y20              XPJLWQ    2022-03-31       2022-03-31   \n\n       AWD_LEVEL_MILE_QTY  NUM_PAX OD_ORIGIN_AIRPRT_IATA_CD  \\\n4817                25000        1                   CVG      \n34387               60000        1                   CDG      \n18976               55000        2                   SXM      \n27643               55000        2                   SXM      \n8167                30000        1                   SXM      \n...                   ...      ...                      ...   \n68171               50000        1                   SFO      \n33139               63000        3                   SRQ      \n12906               27500        1                   SXM      \n56017              121000        1                   MIA      \n79834               27000        1                   DFW      \n\n      OD_DESTNTN_AIRPRT_IATA_CD  AP  RAW_AP  ...  LAST_EMAIL  AGE_LAST_EMAIL  \\\n4817                     CLT      0       0  ...    2.346353       77.346353   \n34387                    LAX      7       7  ...    3.328380       96.328380   \n18976                    MIA      2       2  ...    0.000000       71.000000   \n27643                    MIA      2       2  ...    0.000000       71.000000   \n8167                     MIA      2       2  ...    0.000000       71.000000   \n...                         ...  ..     ...  ...         ...             ...   \n68171                    CLT      8       8  ...   -0.211229       83.788771   \n33139                    STL      1       1  ...   -0.000664       84.999336   \n12906                    MIA      8       8  ...   -1.074486       61.925514   \n56017                    CMH      8       8  ...    1.355643       81.355643   \n79834                    DEN      1       1  ...    0.000000       85.000000   \n\n       risk_feature1  risk_feature2  risk_feature3  risk_feature4  \\\n4817        1.880814       3.333333       1.465980     154.692706   \n34387      -5.026872       1.000000       0.477815     192.656759   \n18976      -2.538867       2.000000       0.948073     284.000000   \n27643      -2.538867       2.000000       0.948073     284.000000   \n8167       -2.538867       2.000000       0.895424     284.000000   \n...              ...            ...            ...            ...   \n68171      -9.310381       0.909091       0.427179      83.788771   \n33139      -1.881743       2.500000       1.199835      84.999336   \n12906      -8.759668       0.476190       0.211397     123.851028   \n56017      -7.091515       1.818182       0.462071      81.355643   \n79834      -2.362605       2.500000       1.107841      85.000000   \n\n       risk_feature5  risk_feature6  safe_feature1  decision_function  \n4817        2.000000     158.795880              9        1260.282427  \n34387       0.250000      24.444538             14        1204.476045  \n18976       1.333333      56.143488              8        1082.116265  \n27643       1.333333      56.143488              8        1082.116265  \n8167        1.333333      55.948357              8        1081.767368  \n...              ...            ...            ...                ...  \n68171       0.111111       7.246766             10         593.827710  \n33139       0.500000      18.645108             14         593.491489  \n12906       0.222222       8.665038             12         592.041467  \n56017       0.111111       7.734799              9         587.903548  \n79834       0.500000      16.883068             14         587.435416  \n\n[100 rows x 95 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LYLTY_ACCT_ID</th>\n      <th>PNR_LOCTR_ID</th>\n      <th>PNR_CREATE_DT</th>\n      <th>AWD_PKG_ISSUE_DT</th>\n      <th>AWD_LEVEL_MILE_QTY</th>\n      <th>NUM_PAX</th>\n      <th>OD_ORIGIN_AIRPRT_IATA_CD</th>\n      <th>OD_DESTNTN_AIRPRT_IATA_CD</th>\n      <th>AP</th>\n      <th>RAW_AP</th>\n      <th>...</th>\n      <th>LAST_EMAIL</th>\n      <th>AGE_LAST_EMAIL</th>\n      <th>risk_feature1</th>\n      <th>risk_feature2</th>\n      <th>risk_feature3</th>\n      <th>risk_feature4</th>\n      <th>risk_feature5</th>\n      <th>risk_feature6</th>\n      <th>safe_feature1</th>\n      <th>decision_function</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4817</th>\n      <td>M546732</td>\n      <td>FKSZNB</td>\n      <td>2022-04-01</td>\n      <td>2022-04-01</td>\n      <td>25000</td>\n      <td>1</td>\n      <td>CVG</td>\n      <td>CLT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2.346353</td>\n      <td>77.346353</td>\n      <td>1.880814</td>\n      <td>3.333333</td>\n      <td>1.465980</td>\n      <td>154.692706</td>\n      <td>2.000000</td>\n      <td>158.795880</td>\n      <td>9</td>\n      <td>1260.282427</td>\n    </tr>\n    <tr>\n      <th>34387</th>\n      <td>PDB4246</td>\n      <td>HHEZUP</td>\n      <td>2022-03-26</td>\n      <td>2022-03-26</td>\n      <td>60000</td>\n      <td>1</td>\n      <td>CDG</td>\n      <td>LAX</td>\n      <td>7</td>\n      <td>7</td>\n      <td>...</td>\n      <td>3.328380</td>\n      <td>96.328380</td>\n      <td>-5.026872</td>\n      <td>1.000000</td>\n      <td>0.477815</td>\n      <td>192.656759</td>\n      <td>0.250000</td>\n      <td>24.444538</td>\n      <td>14</td>\n      <td>1204.476045</td>\n    </tr>\n    <tr>\n      <th>18976</th>\n      <td>965T5L4</td>\n      <td>UPMFKA</td>\n      <td>2022-04-01</td>\n      <td>2022-04-01</td>\n      <td>55000</td>\n      <td>2</td>\n      <td>SXM</td>\n      <td>MIA</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>71.000000</td>\n      <td>-2.538867</td>\n      <td>2.000000</td>\n      <td>0.948073</td>\n      <td>284.000000</td>\n      <td>1.333333</td>\n      <td>56.143488</td>\n      <td>8</td>\n      <td>1082.116265</td>\n    </tr>\n    <tr>\n      <th>27643</th>\n      <td>965T5L4</td>\n      <td>UPMFKA</td>\n      <td>2022-04-01</td>\n      <td>2022-04-01</td>\n      <td>55000</td>\n      <td>2</td>\n      <td>SXM</td>\n      <td>MIA</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>71.000000</td>\n      <td>-2.538867</td>\n      <td>2.000000</td>\n      <td>0.948073</td>\n      <td>284.000000</td>\n      <td>1.333333</td>\n      <td>56.143488</td>\n      <td>8</td>\n      <td>1082.116265</td>\n    </tr>\n    <tr>\n      <th>8167</th>\n      <td>965T5L4</td>\n      <td>VUEINX</td>\n      <td>2022-04-01</td>\n      <td>2022-04-01</td>\n      <td>30000</td>\n      <td>1</td>\n      <td>SXM</td>\n      <td>MIA</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>71.000000</td>\n      <td>-2.538867</td>\n      <td>2.000000</td>\n      <td>0.895424</td>\n      <td>284.000000</td>\n      <td>1.333333</td>\n      <td>55.948357</td>\n      <td>8</td>\n      <td>1081.767368</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>68171</th>\n      <td>2E34VP2</td>\n      <td>SRRHGO</td>\n      <td>2022-03-24</td>\n      <td>2022-03-25</td>\n      <td>50000</td>\n      <td>1</td>\n      <td>SFO</td>\n      <td>CLT</td>\n      <td>8</td>\n      <td>8</td>\n      <td>...</td>\n      <td>-0.211229</td>\n      <td>83.788771</td>\n      <td>-9.310381</td>\n      <td>0.909091</td>\n      <td>0.427179</td>\n      <td>83.788771</td>\n      <td>0.111111</td>\n      <td>7.246766</td>\n      <td>10</td>\n      <td>593.827710</td>\n    </tr>\n    <tr>\n      <th>33139</th>\n      <td>2KB1E70</td>\n      <td>HSUKDP</td>\n      <td>2022-04-02</td>\n      <td>2022-04-02</td>\n      <td>63000</td>\n      <td>3</td>\n      <td>SRQ</td>\n      <td>STL</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.000664</td>\n      <td>84.999336</td>\n      <td>-1.881743</td>\n      <td>2.500000</td>\n      <td>1.199835</td>\n      <td>84.999336</td>\n      <td>0.500000</td>\n      <td>18.645108</td>\n      <td>14</td>\n      <td>593.491489</td>\n    </tr>\n    <tr>\n      <th>12906</th>\n      <td>287T7R4</td>\n      <td>CBFBUR</td>\n      <td>2022-03-27</td>\n      <td>2022-03-28</td>\n      <td>27500</td>\n      <td>1</td>\n      <td>SXM</td>\n      <td>MIA</td>\n      <td>8</td>\n      <td>8</td>\n      <td>...</td>\n      <td>-1.074486</td>\n      <td>61.925514</td>\n      <td>-8.759668</td>\n      <td>0.476190</td>\n      <td>0.211397</td>\n      <td>123.851028</td>\n      <td>0.222222</td>\n      <td>8.665038</td>\n      <td>12</td>\n      <td>592.041467</td>\n    </tr>\n    <tr>\n      <th>56017</th>\n      <td>4AF6858</td>\n      <td>VSPLBB</td>\n      <td>2022-03-23</td>\n      <td>2022-03-23</td>\n      <td>121000</td>\n      <td>1</td>\n      <td>MIA</td>\n      <td>CMH</td>\n      <td>8</td>\n      <td>8</td>\n      <td>...</td>\n      <td>1.355643</td>\n      <td>81.355643</td>\n      <td>-7.091515</td>\n      <td>1.818182</td>\n      <td>0.462071</td>\n      <td>81.355643</td>\n      <td>0.111111</td>\n      <td>7.734799</td>\n      <td>9</td>\n      <td>587.903548</td>\n    </tr>\n    <tr>\n      <th>79834</th>\n      <td>9Y02Y20</td>\n      <td>XPJLWQ</td>\n      <td>2022-03-31</td>\n      <td>2022-03-31</td>\n      <td>27000</td>\n      <td>1</td>\n      <td>DFW</td>\n      <td>DEN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>85.000000</td>\n      <td>-2.362605</td>\n      <td>2.500000</td>\n      <td>1.107841</td>\n      <td>85.000000</td>\n      <td>0.500000</td>\n      <td>16.883068</td>\n      <td>14</td>\n      <td>587.435416</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 95 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649371854915
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import umap\r\n",
        "#import umap.plot\r\n",
        "#import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "#mapper = umap.UMAP(random_state=42).fit(dfTestCopy)\r\n",
        "#umap.plot.points(mapper, labels=dfTestCopy['decision_function']>800)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Numba needs NumPy 1.21 or less",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/tf_2.3.1/lib/python3.8/site-packages/umap/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn, catch_warnings, simplefilter\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mumap_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UMAP\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n",
            "File \u001b[0;32m/anaconda/envs/tf_2.3.1/lib/python3.8/site-packages/umap/umap_.py:28\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tril \u001b[38;5;28;01mas\u001b[39;00m sparse_tril, triu \u001b[38;5;28;01mas\u001b[39;00m sparse_triu\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsgraph\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistances\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdist\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msparse\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/tf_2.3.1/lib/python3.8/site-packages/numba/__init__.py:200\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    199\u001b[0m _ensure_llvm()\n\u001b[0;32m--> 200\u001b[0m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# we know llvmlite is working as the above tests passed, import it now as SVML\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# needs to mutate runtime options (sets the `-vector-library`).\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mllvmlite\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/tf_2.3.1/lib/python3.8/site-packages/numba/__init__.py:140\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.18 or greater\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m numpy_version \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.21 or less\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: Numba needs NumPy 1.21 or less"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649371858142
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#clf = IsolationForest(n_estimators=100, max_samples=4096, random_state=0).fit(dfCopy[predictors])\r\n",
        "\r\n",
        "#dd = pd.DataFrame(clf.decision_function(dfTestCopy[predictors]))\r\n",
        "#dfTest['decision_function'] = dd\r\n",
        "#out = dfTest.nsmallest(n=100, columns='decision_function')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649296631708
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\r\n",
        "print(sys.version)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648217013948
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "tf_2.3.1",
      "language": "python",
      "display_name": "tf_2.3.1"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "tf_2.3.1"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}