{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install ~/cloudfiles/code/software/PyPeanuts/latest/peanuts-0.6.5-py3-none-any.whl --force-reinstall"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1649292481490
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import peanuts\r\n",
        "from peanuts.AML.orion import *\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "print(tf.version.VERSION) # shuold be 2.3.1\r\n",
        "from model import EfficientGAN\r\n",
        "\r\n",
        "username='746220'\r\n",
        "orion = Orion(user=username)\r\n",
        "\r\n",
        "#import umap\r\n",
        "#import umap.plot\r\n",
        "#import matplotlib.pyplot as plt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2.3.1\nðŸ””\u001b[1m Just a Reminder: Is your key vault name following the naming convention: ba-<n|p>-z<eaus|weus>-<user>-kv? If NO, please specify your key vault name.\u001b[0m\nðŸ””\u001b[1m Just a Reminder: Do you have a secret with name corpaaid-pw stored in your key vault? If NO, please specify your secret name.\u001b[0m\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649292489625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_path_loader(data_source, scoring_training_ind):\r\n",
        "    \"\"\"\r\n",
        "    This function loads query paths based on input args.\r\n",
        "    We have saved queries in these locations.\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    if data_source == 'trans':\r\n",
        "      if scoring_training_ind=='training':\r\n",
        "        sql_path=\"../AWD_TRANS_Databricks_Query.sql\"  # _Feb24-1.txt\"\r\n",
        "      else:\r\n",
        "        # sql_path=\"/dbfs/FileStore/tables/data_query_test_Mar4.txt\"\r\n",
        "        sql_path=\"../AWD_TRANS_Databricks_Query.sql\"\r\n",
        "#       data_query_updated_Feb-1.txt\"\r\n",
        "      #data_query_Jan-3.txt\" data_query_Jan_vol.txt\"  data_query_Jan_vol_cast.txt\r\n",
        "#     elif data_source == \"clickstream\":\r\n",
        "#             sql_path = \"./\"\r\n",
        "    return sql_path\r\n",
        "\r\n",
        "# sql_path_loader('trans')\r\n",
        "\r\n",
        "def sql_renderer(data_source, scoring_training_ind, start_date, end_date, print_sql=False):\r\n",
        "    \"\"\"\r\n",
        "    This function renders the query based on input args\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    sql_path = sql_path_loader(data_source = data_source, scoring_training_ind=scoring_training_ind )\r\n",
        "    sql = open(sql_path, 'r').read()\r\n",
        "#     if scoring_training_ind=='training':\r\n",
        "    sql = sql.format(lb=start_date, ub=end_date)\r\n",
        "#     else:\r\n",
        "#       sql = sql.format(CURRENT_DATE=date)\r\n",
        "    if print_sql:\r\n",
        "        print(sql)\r\n",
        "    return sql\r\n",
        "  \r\n",
        "def data_retriever_fun(data_source,scoring_training_ind, start_date, end_date, print_sql):\r\n",
        "    \"\"\"\r\n",
        "    This function retrieves records from mosaic tables\r\n",
        "    \"\"\"\r\n",
        "        \r\n",
        "    if (data_source != \"trans\") & (data_source != \"clickstream\"):\r\n",
        "        print(\"### ERROR: data source should be either trans or clickstream ###\")\r\n",
        "        return\r\n",
        "    elif (start_date == None):\r\n",
        "        print(\"### ERROR: Provide date in format of 'yyyy-mm-dd' ###\")\r\n",
        "        return\r\n",
        "    else:\r\n",
        "            sql = sql_renderer(data_source = data_source, scoring_training_ind=scoring_training_ind, \r\n",
        "            start_date=start_date, end_date=end_date, print_sql = print_sql)\r\n",
        "            retrieved_df = orion.mq(sql)#pd.read_sql(sql)\r\n",
        "            return retrieved_df"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649292489855
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sql_path=\"AWD_TRANS_Databricks_Query.sql\"\r\n",
        "#sql = open(sql_path, 'r').read()\r\n",
        "#start_date='2022-03-24'\r\n",
        "#end_date='2022-03-30'\r\n",
        "#sql = sql.format(lb=start_date, ub=end_date, binHist='(1)')\r\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649292490094
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_test=data_retriever_fun(data_source='trans', scoring_training_ind='scoring', start_date='2022-03-30', end_date='2022-04-05', print_sql=False)\r\n",
        "sdf=data_retriever_fun(data_source='trans', scoring_training_ind='training', start_date='2022-02-28', end_date='2022-03-29', print_sql=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\npandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649293418552
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sdf.display()\r\n",
        "# without filter\r\n",
        "indices=['LYLTY_ACCT_ID', 'PNR_LOCTR_ID', 'PNR_CREATE_DT', 'AWD_PKG_ISSUE_DT']\r\n",
        "categorical=['OPERAT_AIRLN','ORIGIN_RM_WRLD_REGION_CD','DESTNTN_RM_WRLD_REGION_CD']\r\n",
        "#, 'OPERAT_AIRLN_IATA_CD2', 'OD_ORIGIN_AIRPRT_IATA_CD','OD_DESTNTN_AIRPRT_IATA_CD','ORIGIN_CNTRY_CD','ORIGIN_RM_WRLD_REGION_CD','DESTNTN_CNTRY_CD','DESTNTN_RM_WRLD_REGION_CD'\r\n",
        "#  'VISITED_BEFORE_STATE'\r\n",
        "#'AWD_LEVEL_MILE_QTY','NUM_PAX','SAFE_AIRPRT_IND','FLAGGED_AIRPRT_IND', \r\n",
        "numericals=['AP','PAX_LYLTY_IND', \r\n",
        "            'VISITED_BEFORE_AIRPORT',\r\n",
        "            #'VISITED_BEFORE_CNTRY',\r\n",
        "            'USED_BEFORE_ARILN',\r\n",
        "            'ONE_WAY', 'SHORT_AP_OK',\r\n",
        "            'SEEN_ITIN',\r\n",
        "            #'SAFE_VS_FLAGGED_CNTRY', \r\n",
        "            'BIN_HIST', 'MULTI_REDEEM', 'EMAIL_CHANGE30', \r\n",
        "            'U_AP', 'AGE45', 'AGE_logEMAIL',\r\n",
        "            'LAST_EMAIL',\r\n",
        "            'AGE_LAST_EMAIL',\r\n",
        "            #'HOME_AIRPRT',\r\n",
        "            #'HOME_STATE',\r\n",
        "            #'HOME_RESDNC_CNTRY',\r\n",
        "            #'HOME_ADV',\r\n",
        "            'FLAGGED_CNTRY_ALERT',\r\n",
        "            'FLAGGED_AIRPRT_ALERT',\r\n",
        "            'risk_feature1', \r\n",
        "            'risk_feature2',\r\n",
        "            'risk_feature3',\r\n",
        "            'risk_feature4',\r\n",
        "            #'risk_feature5',\r\n",
        "            'risk_feature6',\r\n",
        " #           'safe_feature1',\r\n",
        " #           'FREQ_USED_ARILN',\r\n",
        " #           'FREQ_DESTNTN_CNTRY',\r\n",
        " #           'FREQ_ORIGIN_CNTRY',\r\n",
        " #           'FREQ_CNTRY',\r\n",
        "#            'FREQ_ORIGIN_AIRPRT',\r\n",
        "#            'FREQ_DESTNTN_AIRPRT',\r\n",
        " #           'FREQ_AIRPORT',\r\n",
        "           ]\r\n",
        "\r\n",
        "# 'FLAGGED_CNTRY_ALERT', 'SAFE_CNTRY_OK',\r\n",
        "#  'SAFE_VS_FLAGGED_CNTRY',\r\n",
        "#  'NUM_HIST',\r\n",
        "#  'DAYS_SINCE_LAST'\r\n",
        "predictors=numericals+categorical"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649293418758
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sdfNorm = sdf.query('(BIN_HIST == 1) & (NORMAL_TRAN == 1)')\r\n",
        "sdfNorm = sdf.query('(BIN_HIST == 1) & ((NORMAL_TRAN == 1) | (FLOWN_LAST_NM == 1) | (RED_LAST_NM == 1) | (IP_MATCH == 1))')\r\n",
        "\r\n",
        "sdfNorm = sdfNorm.drop_duplicates()\r\n",
        "#sdfFiltered = sdf.filter((sdf.OWNER_IN_FLIGHT != 1) & (sdf.BIN_HIST == 1))\r\n",
        "\r\n",
        "#sdf_test_clean = sdf_test.query('((BIN_HIST == 1) & (RAW_AP <= 9) & ~(NORMAL_TRAN == 1))')\r\n",
        "sdf_test_clean = sdf_test.query('((BIN_HIST == 1) & (RAW_AP <= 9) & ~((NORMAL_TRAN == 1) | (FLOWN_LAST_NM == 1) | (RED_LAST_NM == 1) | (IP_MATCH == 1)))')\r\n",
        "sdf_test_clean = sdf_test_clean.drop_duplicates()\r\n",
        "#predictions=model.transform(sdf_test_clean)\r\n",
        "\r\n",
        "#& sdf.OWNER_IN_FLIGHT != 1 & sdf.PAX_REDEEMED_BEFORE != 1 & sdf.ONE_WAY != 1)\r\n",
        "\r\n",
        "numAfter = len(sdfNorm)\r\n",
        "numBefore = len(sdf)\r\n",
        "print(f\"rows of normal instances {numAfter}\")\r\n",
        "print(f\"rows of all instances {numBefore}\")\r\n",
        "print(f\"reduction percentage AFTER filtering {round(numAfter / numBefore * 100, 2)}\")\r\n",
        "\r\n",
        "print(f\"rows AFTER filtering {len(sdf_test_clean)}\")\r\n",
        "print(f\"rows BEFORE filtering {len(sdf_test)}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649293421454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\r\n",
        "from sklearn.preprocessing import LabelEncoder# creating initial dataframe\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "df = sdfNorm\r\n",
        "dfTest = sdf_test_clean\r\n",
        "\r\n",
        "le = LabelEncoder()\r\n",
        "dfCopy = df.copy()\r\n",
        "dfTestCopy = dfTest.copy()\r\n",
        "\r\n",
        "for col in categorical:\r\n",
        "  dfCopy[col] = le.fit_transform(dfCopy[col])\r\n",
        "  dfTestCopy[col] = le.fit_transform(dfTestCopy[col])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649293422777
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = EfficientGAN()\r\n",
        "model.fit(dfCopy[predictors])\r\n",
        "proba = model.predict(dfTestCopy[predictors])\r\n",
        "dfTest['decision_function'] = proba\r\n",
        "out = dfTest.nsmallest(n=100, columns='decision_function')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649293431275
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out.to_csv('res220330-0405.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649293431488
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import umap\r\n",
        "#import umap.plot\r\n",
        "#import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "#mapper = umap.UMAP(random_state=42).fit(dfTestCopy[predictors])\r\n",
        "#umap.plot.points(mapper)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649293431647
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#clf = IsolationForest(n_estimators=100, max_samples=4096, random_state=0).fit(dfCopy[predictors])\r\n",
        "\r\n",
        "#dd = pd.DataFrame(clf.decision_function(dfTestCopy[predictors]))\r\n",
        "#dfTest['decision_function'] = dd\r\n",
        "#out = dfTest.nsmallest(n=100, columns='decision_function')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\r\n",
        "print(sys.version)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648217013948
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "tf_2.3.1",
      "language": "python",
      "display_name": "tf_2.3.1"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "tf_2.3.1"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}